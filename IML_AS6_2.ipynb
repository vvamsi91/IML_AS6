{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODFfcM5ETi5vi9X74zyIoO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvamsi91/IML_AS6/blob/main/IML_AS6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wBaHzGB6MTf",
        "outputId": "1daf0810-53c4-4266-d00b-c3b373270fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.12)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 339 µs (started: 2023-12-02 00:29:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSyh9vM17jq9",
        "outputId": "75b1ac93-73fd-4d90-c22e-bf481cbfe97b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.9 s (started: 2023-12-02 00:29:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8p1MEc-7pS3",
        "outputId": "159abf9f-463e-483b-892a-eb39964e2303"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b2ffee66690>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.04 ms (started: 2023-12-02 00:31:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean, std = imgs.view(3, -1).mean(dim=1), imgs.view(3, -1).std(dim=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K70moidw8ZAT",
        "outputId": "0ade644b-a426-4ed6-f503-3a62cdf4450e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 73376949.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "time: 25.3 s (started: 2023-12-02 00:34:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVyJzibB9OsL",
        "outputId": "2875e458-337c-4e60-a802-1015b70e7df6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 40.2 ms (started: 2023-12-02 00:37:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d_VYyD-KBQ",
        "outputId": "c3a76023-01d2-4ce7-e89a-9481c5f31395"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 19.3 ms (started: 2023-12-02 00:41:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting Device\n",
        "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Device\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHrdyNaS-RNX",
        "outputId": "fdf9c582-90bc-47ad-8bd0-51518512cf87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.7 ms (started: 2023-12-02 00:47:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTDpd2mG-XzL",
        "outputId": "36e68803-dbd0-4ebd-afa7-904e9261e439"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 928 µs (started: 2023-12-02 00:47:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10('./data', train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_glGMBAp_5fZ",
        "outputId": "b7c6bef5-e5f3-4280-f0ae-10850966dee7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 624 ms (started: 2023-12-02 00:49:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_val = datasets.CIFAR10('./data', train=False, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up4dseCWAHIZ",
        "outputId": "09f7296f-eda7-4a04-a424-fe248f661de4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 497 ms (started: 2023-12-02 00:50:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "first_image, label = cifar10[0]\n",
        "print(first_image.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2UyAndEASRx",
        "outputId": "852d2cc2-06b3-4bac-ca32-e0649ee1f014"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 12.7 ms (started: 2023-12-02 00:51:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(cifar10_val, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAWkXOQsAtMc",
        "outputId": "d01e5046-2d75-47b3-ff54-6a0905c0e0eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.4 ms (started: 2023-12-02 00:54:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Flatten(), nn.Linear(32 * 32 * 3, 512), nn.Tanh(), nn.Linear(512, 10)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uxWoO0FBM9Q",
        "outputId": "ca9d0d82-a7b0-430e-8b1f-e13e0a174162"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 111 ms (started: 2023-12-02 00:55:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, train_loader, test_loader, num_epochs=300, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Testing the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_predicted)\n",
        "    print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti941EF-Be-b",
        "outputId": "846fd428-3271-459d-f860-f7672dacd810"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.98 ms (started: 2023-12-02 00:55:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_model(model, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJ9KBRcBjIS",
        "outputId": "7875614e-a46d-4686-b8f8-f744906a1cdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.7886348081870638, Test Accuracy: 40.94%\n",
            "Epoch 2/300, Loss: 1.6521172705020037, Test Accuracy: 43.15%\n",
            "Epoch 3/300, Loss: 1.5804378465437692, Test Accuracy: 44.45%\n",
            "Epoch 4/300, Loss: 1.5198366514246813, Test Accuracy: 45.26%\n",
            "Epoch 5/300, Loss: 1.4625313013544161, Test Accuracy: 46.44%\n",
            "Epoch 6/300, Loss: 1.4085316710646, Test Accuracy: 47.50%\n",
            "Epoch 7/300, Loss: 1.3539841107580803, Test Accuracy: 47.11%\n",
            "Epoch 8/300, Loss: 1.3031534532744078, Test Accuracy: 47.23%\n",
            "Epoch 9/300, Loss: 1.249340126015632, Test Accuracy: 48.36%\n",
            "Epoch 10/300, Loss: 1.1990976107097633, Test Accuracy: 47.90%\n",
            "Epoch 11/300, Loss: 1.147438968516891, Test Accuracy: 48.39%\n",
            "Epoch 12/300, Loss: 1.0958708692496966, Test Accuracy: 49.10%\n",
            "Epoch 13/300, Loss: 1.0460041413990564, Test Accuracy: 48.73%\n",
            "Epoch 14/300, Loss: 0.9943198018247931, Test Accuracy: 48.12%\n",
            "Epoch 15/300, Loss: 0.9466876947223873, Test Accuracy: 48.06%\n",
            "Epoch 16/300, Loss: 0.8974496146195681, Test Accuracy: 48.03%\n",
            "Epoch 17/300, Loss: 0.8493160491216968, Test Accuracy: 48.20%\n",
            "Epoch 18/300, Loss: 0.8030849673087522, Test Accuracy: 47.89%\n",
            "Epoch 19/300, Loss: 0.7584418158308482, Test Accuracy: 47.59%\n",
            "Epoch 20/300, Loss: 0.7151811761079655, Test Accuracy: 47.85%\n",
            "Epoch 21/300, Loss: 0.6756449853161246, Test Accuracy: 46.26%\n",
            "Epoch 22/300, Loss: 0.6319736301021857, Test Accuracy: 48.21%\n",
            "Epoch 23/300, Loss: 0.5908622399439662, Test Accuracy: 47.18%\n",
            "Epoch 24/300, Loss: 0.5566875617700895, Test Accuracy: 47.14%\n",
            "Epoch 25/300, Loss: 0.518112089501614, Test Accuracy: 46.81%\n",
            "Epoch 26/300, Loss: 0.48450431075144945, Test Accuracy: 46.79%\n",
            "Epoch 27/300, Loss: 0.4544286360381432, Test Accuracy: 46.92%\n",
            "Epoch 28/300, Loss: 0.4219303291364885, Test Accuracy: 47.37%\n",
            "Epoch 29/300, Loss: 0.3913330497912543, Test Accuracy: 46.04%\n",
            "Epoch 30/300, Loss: 0.36696073348066094, Test Accuracy: 47.30%\n",
            "Epoch 31/300, Loss: 0.3374213149731768, Test Accuracy: 46.83%\n",
            "Epoch 32/300, Loss: 0.31385827586483817, Test Accuracy: 46.64%\n",
            "Epoch 33/300, Loss: 0.29224866034697816, Test Accuracy: 46.86%\n",
            "Epoch 34/300, Loss: 0.2670081588925266, Test Accuracy: 46.87%\n",
            "Epoch 35/300, Loss: 0.24813721908622266, Test Accuracy: 46.66%\n",
            "Epoch 36/300, Loss: 0.23375389504264885, Test Accuracy: 45.88%\n",
            "Epoch 37/300, Loss: 0.2140110737321778, Test Accuracy: 44.58%\n",
            "Epoch 38/300, Loss: 0.1977330784617863, Test Accuracy: 46.29%\n",
            "Epoch 39/300, Loss: 0.18204637396644494, Test Accuracy: 45.95%\n",
            "Epoch 40/300, Loss: 0.16695387970587036, Test Accuracy: 46.55%\n",
            "Epoch 41/300, Loss: 0.15741203715089264, Test Accuracy: 45.88%\n",
            "Epoch 42/300, Loss: 0.14299652590079714, Test Accuracy: 46.73%\n",
            "Epoch 43/300, Loss: 0.13252591986926565, Test Accuracy: 47.06%\n",
            "Epoch 44/300, Loss: 0.12256554260692647, Test Accuracy: 46.26%\n",
            "Epoch 45/300, Loss: 0.11413938269109697, Test Accuracy: 46.65%\n",
            "Epoch 46/300, Loss: 0.10578923942479504, Test Accuracy: 46.28%\n",
            "Epoch 47/300, Loss: 0.09701926458772374, Test Accuracy: 46.52%\n",
            "Epoch 48/300, Loss: 0.09125530832016308, Test Accuracy: 46.09%\n",
            "Epoch 49/300, Loss: 0.08323960484351703, Test Accuracy: 45.85%\n",
            "Epoch 50/300, Loss: 0.07793031386096777, Test Accuracy: 46.47%\n",
            "Epoch 51/300, Loss: 0.07340179563703174, Test Accuracy: 46.87%\n",
            "Epoch 52/300, Loss: 0.06789153587890602, Test Accuracy: 46.78%\n",
            "Epoch 53/300, Loss: 0.06405183663013762, Test Accuracy: 46.37%\n",
            "Epoch 54/300, Loss: 0.0600957814508707, Test Accuracy: 46.46%\n",
            "Epoch 55/300, Loss: 0.05622955678139294, Test Accuracy: 46.63%\n",
            "Epoch 56/300, Loss: 0.05343070523771657, Test Accuracy: 46.30%\n",
            "Epoch 57/300, Loss: 0.050525530729435685, Test Accuracy: 46.39%\n",
            "Epoch 58/300, Loss: 0.04866047613251232, Test Accuracy: 46.61%\n",
            "Epoch 59/300, Loss: 0.04477761479205454, Test Accuracy: 46.35%\n",
            "Epoch 60/300, Loss: 0.04320085038545989, Test Accuracy: 46.14%\n",
            "Epoch 61/300, Loss: 0.04076752209498458, Test Accuracy: 46.08%\n",
            "Epoch 62/300, Loss: 0.03865865762783447, Test Accuracy: 46.75%\n",
            "Epoch 63/300, Loss: 0.03657484882626199, Test Accuracy: 46.46%\n",
            "Epoch 64/300, Loss: 0.03542648075280743, Test Accuracy: 46.50%\n",
            "Epoch 65/300, Loss: 0.033578440731108876, Test Accuracy: 46.75%\n",
            "Epoch 66/300, Loss: 0.03269095509417322, Test Accuracy: 46.60%\n",
            "Epoch 67/300, Loss: 0.030699097605628306, Test Accuracy: 46.80%\n",
            "Epoch 68/300, Loss: 0.02998452520347126, Test Accuracy: 46.49%\n",
            "Epoch 69/300, Loss: 0.028528229944808355, Test Accuracy: 46.47%\n",
            "Epoch 70/300, Loss: 0.02694758165255904, Test Accuracy: 46.21%\n",
            "Epoch 71/300, Loss: 0.02668847565218015, Test Accuracy: 46.48%\n",
            "Epoch 72/300, Loss: 0.025075945568819764, Test Accuracy: 46.66%\n",
            "Epoch 73/300, Loss: 0.02466983015107388, Test Accuracy: 46.84%\n",
            "Epoch 74/300, Loss: 0.02402608683398345, Test Accuracy: 46.53%\n",
            "Epoch 75/300, Loss: 0.023083230435862537, Test Accuracy: 46.30%\n",
            "Epoch 76/300, Loss: 0.022875311340533687, Test Accuracy: 45.97%\n",
            "Epoch 77/300, Loss: 0.021731449574141533, Test Accuracy: 46.55%\n",
            "Epoch 78/300, Loss: 0.021448273174178693, Test Accuracy: 46.52%\n",
            "Epoch 79/300, Loss: 0.020670220698572585, Test Accuracy: 46.26%\n",
            "Epoch 80/300, Loss: 0.0195862539636921, Test Accuracy: 46.81%\n",
            "Epoch 81/300, Loss: 0.019641837506165927, Test Accuracy: 46.74%\n",
            "Epoch 82/300, Loss: 0.01876176614671831, Test Accuracy: 46.37%\n",
            "Epoch 83/300, Loss: 0.01837130212919192, Test Accuracy: 46.63%\n",
            "Epoch 84/300, Loss: 0.01816597857267637, Test Accuracy: 46.64%\n",
            "Epoch 85/300, Loss: 0.017544476555211092, Test Accuracy: 46.46%\n",
            "Epoch 86/300, Loss: 0.016873627706232432, Test Accuracy: 46.45%\n",
            "Epoch 87/300, Loss: 0.017143391363825637, Test Accuracy: 46.52%\n",
            "Epoch 88/300, Loss: 0.016380528962896258, Test Accuracy: 46.51%\n",
            "Epoch 89/300, Loss: 0.015886996532489456, Test Accuracy: 46.32%\n",
            "Epoch 90/300, Loss: 0.015363656431591462, Test Accuracy: 46.62%\n",
            "Epoch 91/300, Loss: 0.014941332523632968, Test Accuracy: 46.39%\n",
            "Epoch 92/300, Loss: 0.01471734142839022, Test Accuracy: 46.36%\n",
            "Epoch 93/300, Loss: 0.014288926734848238, Test Accuracy: 46.58%\n",
            "Epoch 94/300, Loss: 0.014111164306610422, Test Accuracy: 46.30%\n",
            "Epoch 95/300, Loss: 0.013687521494538907, Test Accuracy: 46.27%\n",
            "Epoch 96/300, Loss: 0.013534353128965093, Test Accuracy: 46.33%\n",
            "Epoch 97/300, Loss: 0.013250522929531541, Test Accuracy: 46.49%\n",
            "Epoch 98/300, Loss: 0.012950430891726235, Test Accuracy: 46.56%\n",
            "Epoch 99/300, Loss: 0.012681678208622007, Test Accuracy: 46.68%\n",
            "Epoch 100/300, Loss: 0.012520023269765913, Test Accuracy: 46.49%\n",
            "Epoch 101/300, Loss: 0.012335369779930348, Test Accuracy: 46.60%\n",
            "Epoch 102/300, Loss: 0.012068102038533963, Test Accuracy: 46.37%\n",
            "Epoch 103/300, Loss: 0.011870389203025565, Test Accuracy: 46.45%\n",
            "Epoch 104/300, Loss: 0.011635880608359496, Test Accuracy: 46.39%\n",
            "Epoch 105/300, Loss: 0.011446556186044895, Test Accuracy: 46.22%\n",
            "Epoch 106/300, Loss: 0.011449126720962353, Test Accuracy: 46.39%\n",
            "Epoch 107/300, Loss: 0.011080324867894004, Test Accuracy: 46.44%\n",
            "Epoch 108/300, Loss: 0.01091612842510754, Test Accuracy: 46.53%\n",
            "Epoch 109/300, Loss: 0.010745574411550586, Test Accuracy: 46.41%\n",
            "Epoch 110/300, Loss: 0.010496180533161547, Test Accuracy: 46.47%\n",
            "Epoch 111/300, Loss: 0.01035216191970646, Test Accuracy: 46.69%\n",
            "Epoch 112/300, Loss: 0.010294637492049298, Test Accuracy: 46.31%\n",
            "Epoch 113/300, Loss: 0.010068107112141008, Test Accuracy: 46.57%\n",
            "Epoch 114/300, Loss: 0.009943575087353176, Test Accuracy: 46.46%\n",
            "Epoch 115/300, Loss: 0.009806347389122136, Test Accuracy: 46.58%\n",
            "Epoch 116/300, Loss: 0.009609846772133866, Test Accuracy: 46.71%\n",
            "Epoch 117/300, Loss: 0.009482827100733573, Test Accuracy: 46.40%\n",
            "Epoch 118/300, Loss: 0.009367233553695148, Test Accuracy: 46.42%\n",
            "Epoch 119/300, Loss: 0.009251358316137537, Test Accuracy: 46.31%\n",
            "Epoch 120/300, Loss: 0.00911956567434035, Test Accuracy: 46.59%\n",
            "Epoch 121/300, Loss: 0.00893467967443154, Test Accuracy: 46.32%\n",
            "Epoch 122/300, Loss: 0.00887006637357266, Test Accuracy: 46.53%\n",
            "Epoch 123/300, Loss: 0.008757781855862108, Test Accuracy: 46.43%\n",
            "Epoch 124/300, Loss: 0.008623649449023923, Test Accuracy: 46.31%\n",
            "Epoch 125/300, Loss: 0.008564376571082813, Test Accuracy: 46.44%\n",
            "Epoch 126/300, Loss: 0.008428683381418025, Test Accuracy: 46.05%\n",
            "Epoch 127/300, Loss: 0.008314380125945252, Test Accuracy: 46.52%\n",
            "Epoch 128/300, Loss: 0.008205748831415912, Test Accuracy: 46.30%\n",
            "Epoch 129/300, Loss: 0.008111260352883861, Test Accuracy: 46.58%\n",
            "Epoch 130/300, Loss: 0.007993335385168696, Test Accuracy: 46.71%\n",
            "Epoch 131/300, Loss: 0.007903217812922622, Test Accuracy: 46.24%\n",
            "Epoch 132/300, Loss: 0.00781233190566001, Test Accuracy: 46.54%\n",
            "Epoch 133/300, Loss: 0.00770140274502909, Test Accuracy: 46.56%\n",
            "Epoch 134/300, Loss: 0.0076539544820647286, Test Accuracy: 46.33%\n",
            "Epoch 135/300, Loss: 0.007530021327932056, Test Accuracy: 46.41%\n",
            "Epoch 136/300, Loss: 0.007434082744399983, Test Accuracy: 46.60%\n",
            "Epoch 137/300, Loss: 0.0073594021711019435, Test Accuracy: 46.49%\n",
            "Epoch 138/300, Loss: 0.007285498056122205, Test Accuracy: 46.58%\n",
            "Epoch 139/300, Loss: 0.0071995996166096905, Test Accuracy: 46.53%\n",
            "Epoch 140/300, Loss: 0.007124542555416042, Test Accuracy: 46.42%\n",
            "Epoch 141/300, Loss: 0.00705536986166112, Test Accuracy: 46.52%\n",
            "Epoch 142/300, Loss: 0.006963541256341314, Test Accuracy: 46.42%\n",
            "Epoch 143/300, Loss: 0.0068913316613352805, Test Accuracy: 46.43%\n",
            "Epoch 144/300, Loss: 0.006836607304454727, Test Accuracy: 46.60%\n",
            "Epoch 145/300, Loss: 0.006761622746246828, Test Accuracy: 46.42%\n",
            "Epoch 146/300, Loss: 0.006673188021457775, Test Accuracy: 46.44%\n",
            "Epoch 147/300, Loss: 0.006614029655228258, Test Accuracy: 46.43%\n",
            "Epoch 148/300, Loss: 0.006542946558036935, Test Accuracy: 46.21%\n",
            "Epoch 149/300, Loss: 0.006486058564229808, Test Accuracy: 46.51%\n",
            "Epoch 150/300, Loss: 0.006419555968423246, Test Accuracy: 46.41%\n",
            "Epoch 151/300, Loss: 0.006365720535701788, Test Accuracy: 46.37%\n",
            "Epoch 152/300, Loss: 0.006286170895515881, Test Accuracy: 46.45%\n",
            "Epoch 153/300, Loss: 0.006236795647491677, Test Accuracy: 46.44%\n",
            "Epoch 154/300, Loss: 0.006177555565452364, Test Accuracy: 46.41%\n",
            "Epoch 155/300, Loss: 0.0061134056298995315, Test Accuracy: 46.60%\n",
            "Epoch 156/300, Loss: 0.006044875722115124, Test Accuracy: 46.34%\n",
            "Epoch 157/300, Loss: 0.005995429740945784, Test Accuracy: 46.16%\n",
            "Epoch 158/300, Loss: 0.005953047102643743, Test Accuracy: 46.54%\n",
            "Epoch 159/300, Loss: 0.00588813055216103, Test Accuracy: 46.36%\n",
            "Epoch 160/300, Loss: 0.005829815159034001, Test Accuracy: 46.30%\n",
            "Epoch 161/300, Loss: 0.005788469020788506, Test Accuracy: 46.33%\n",
            "Epoch 162/300, Loss: 0.0057194081509887446, Test Accuracy: 46.42%\n",
            "Epoch 163/300, Loss: 0.0056900763891634945, Test Accuracy: 46.34%\n",
            "Epoch 164/300, Loss: 0.0056314890672734584, Test Accuracy: 46.43%\n",
            "Epoch 165/300, Loss: 0.0055843182532289565, Test Accuracy: 46.34%\n",
            "Epoch 166/300, Loss: 0.005529932334532893, Test Accuracy: 46.25%\n",
            "Epoch 167/300, Loss: 0.005480694986006301, Test Accuracy: 46.41%\n",
            "Epoch 168/300, Loss: 0.005439800962416058, Test Accuracy: 46.35%\n",
            "Epoch 169/300, Loss: 0.00538251282300464, Test Accuracy: 46.50%\n",
            "Epoch 170/300, Loss: 0.005337228367828495, Test Accuracy: 46.44%\n",
            "Epoch 171/300, Loss: 0.005294682984183747, Test Accuracy: 46.41%\n",
            "Epoch 172/300, Loss: 0.005262249360315058, Test Accuracy: 46.17%\n",
            "Epoch 173/300, Loss: 0.005215800102288886, Test Accuracy: 46.34%\n",
            "Epoch 174/300, Loss: 0.005173319725764252, Test Accuracy: 46.43%\n",
            "Epoch 175/300, Loss: 0.0051209048735381835, Test Accuracy: 46.55%\n",
            "Epoch 176/300, Loss: 0.005078459693022401, Test Accuracy: 46.36%\n",
            "Epoch 177/300, Loss: 0.0050439278415499, Test Accuracy: 46.53%\n",
            "Epoch 178/300, Loss: 0.005007016551767262, Test Accuracy: 46.35%\n",
            "Epoch 179/300, Loss: 0.004973149739690864, Test Accuracy: 46.33%\n",
            "Epoch 180/300, Loss: 0.004930987740078522, Test Accuracy: 46.23%\n",
            "Epoch 181/300, Loss: 0.004888740459651289, Test Accuracy: 46.47%\n",
            "Epoch 182/300, Loss: 0.004847669434719984, Test Accuracy: 46.27%\n",
            "Epoch 183/300, Loss: 0.004811947973134021, Test Accuracy: 46.40%\n",
            "Epoch 184/300, Loss: 0.00477013222352433, Test Accuracy: 46.48%\n",
            "Epoch 185/300, Loss: 0.004737283959561722, Test Accuracy: 46.22%\n",
            "Epoch 186/300, Loss: 0.00470068693349897, Test Accuracy: 46.44%\n",
            "Epoch 187/300, Loss: 0.004673335423111506, Test Accuracy: 46.30%\n",
            "Epoch 188/300, Loss: 0.004640165088526662, Test Accuracy: 46.41%\n",
            "Epoch 189/300, Loss: 0.004602413316914527, Test Accuracy: 46.46%\n",
            "Epoch 190/300, Loss: 0.004566066762103544, Test Accuracy: 46.37%\n",
            "Epoch 191/300, Loss: 0.004537050017457806, Test Accuracy: 46.43%\n",
            "Epoch 192/300, Loss: 0.004504614870432795, Test Accuracy: 46.47%\n",
            "Epoch 193/300, Loss: 0.004479275698763433, Test Accuracy: 46.32%\n",
            "Epoch 194/300, Loss: 0.004435529055131059, Test Accuracy: 46.36%\n",
            "Epoch 195/300, Loss: 0.004408082138253608, Test Accuracy: 46.41%\n",
            "Epoch 196/300, Loss: 0.004372622498971907, Test Accuracy: 46.43%\n",
            "Epoch 197/300, Loss: 0.0043425731452078255, Test Accuracy: 46.41%\n",
            "Epoch 198/300, Loss: 0.0043176171528944126, Test Accuracy: 46.32%\n",
            "Epoch 199/300, Loss: 0.004283114826224473, Test Accuracy: 46.40%\n",
            "Epoch 200/300, Loss: 0.004257794865243189, Test Accuracy: 46.43%\n",
            "Epoch 201/300, Loss: 0.00422845135209933, Test Accuracy: 46.52%\n",
            "Epoch 202/300, Loss: 0.004198365622382999, Test Accuracy: 46.29%\n",
            "Epoch 203/300, Loss: 0.00417097257086751, Test Accuracy: 46.39%\n",
            "Epoch 204/300, Loss: 0.004140672800074536, Test Accuracy: 46.41%\n",
            "Epoch 205/300, Loss: 0.004115963240898311, Test Accuracy: 46.32%\n",
            "Epoch 206/300, Loss: 0.004081610707603085, Test Accuracy: 46.42%\n",
            "Epoch 207/300, Loss: 0.0040638568183682475, Test Accuracy: 46.41%\n",
            "Epoch 208/300, Loss: 0.004034158541038585, Test Accuracy: 46.38%\n",
            "Epoch 209/300, Loss: 0.004003579805319698, Test Accuracy: 46.52%\n",
            "Epoch 210/300, Loss: 0.003977131998474499, Test Accuracy: 46.42%\n",
            "Epoch 211/300, Loss: 0.0039572251781282595, Test Accuracy: 46.29%\n",
            "Epoch 212/300, Loss: 0.003933481389662026, Test Accuracy: 46.42%\n",
            "Epoch 213/300, Loss: 0.003908129309000768, Test Accuracy: 46.50%\n",
            "Epoch 214/300, Loss: 0.0038802997332473862, Test Accuracy: 46.43%\n",
            "Epoch 215/300, Loss: 0.0038570784199482362, Test Accuracy: 46.50%\n",
            "Epoch 216/300, Loss: 0.0038284156981692368, Test Accuracy: 46.31%\n",
            "Epoch 217/300, Loss: 0.0038081994126786217, Test Accuracy: 46.43%\n",
            "Epoch 218/300, Loss: 0.003789753064999425, Test Accuracy: 46.13%\n",
            "Epoch 219/300, Loss: 0.0037612617273546246, Test Accuracy: 46.32%\n",
            "Epoch 220/300, Loss: 0.003737788517218767, Test Accuracy: 46.47%\n",
            "Epoch 221/300, Loss: 0.003717697059267313, Test Accuracy: 46.28%\n",
            "Epoch 222/300, Loss: 0.0036967343421949648, Test Accuracy: 46.44%\n",
            "Epoch 223/300, Loss: 0.0036737007834225827, Test Accuracy: 46.27%\n",
            "Epoch 224/300, Loss: 0.003653723528231503, Test Accuracy: 46.33%\n",
            "Epoch 225/300, Loss: 0.0036288713273650093, Test Accuracy: 46.33%\n",
            "Epoch 226/300, Loss: 0.0036061756333404162, Test Accuracy: 46.33%\n",
            "Epoch 227/300, Loss: 0.003588431019047591, Test Accuracy: 46.38%\n",
            "Epoch 228/300, Loss: 0.003568144407083405, Test Accuracy: 46.42%\n",
            "Epoch 229/300, Loss: 0.003544409252641817, Test Accuracy: 46.39%\n",
            "Epoch 230/300, Loss: 0.0035226147203877216, Test Accuracy: 46.37%\n",
            "Epoch 231/300, Loss: 0.0035048010469320746, Test Accuracy: 46.34%\n",
            "Epoch 232/300, Loss: 0.003484587505953154, Test Accuracy: 46.38%\n",
            "Epoch 233/300, Loss: 0.003466156128107529, Test Accuracy: 46.38%\n",
            "Epoch 234/300, Loss: 0.0034434198739569603, Test Accuracy: 46.26%\n",
            "Epoch 235/300, Loss: 0.0034248108621204054, Test Accuracy: 46.41%\n",
            "Epoch 236/300, Loss: 0.003407718024144494, Test Accuracy: 46.39%\n",
            "Epoch 237/300, Loss: 0.003387728432504435, Test Accuracy: 46.42%\n",
            "Epoch 238/300, Loss: 0.0033648654688787256, Test Accuracy: 46.28%\n",
            "Epoch 239/300, Loss: 0.003347438299132872, Test Accuracy: 46.45%\n",
            "Epoch 240/300, Loss: 0.003331032436462006, Test Accuracy: 46.39%\n",
            "Epoch 241/300, Loss: 0.0033131123425692833, Test Accuracy: 46.34%\n",
            "Epoch 242/300, Loss: 0.0032924102924368507, Test Accuracy: 46.36%\n",
            "Epoch 243/300, Loss: 0.0032770960729227175, Test Accuracy: 46.48%\n",
            "Epoch 244/300, Loss: 0.0032582972279165275, Test Accuracy: 46.37%\n",
            "Epoch 245/300, Loss: 0.0032412573656154246, Test Accuracy: 46.44%\n",
            "Epoch 246/300, Loss: 0.003223197243902749, Test Accuracy: 46.34%\n",
            "Epoch 247/300, Loss: 0.0032095514058826046, Test Accuracy: 46.42%\n",
            "Epoch 248/300, Loss: 0.0031895194375012796, Test Accuracy: 46.45%\n",
            "Epoch 249/300, Loss: 0.0031713938045745058, Test Accuracy: 46.33%\n",
            "Epoch 250/300, Loss: 0.003157238603268064, Test Accuracy: 46.50%\n",
            "Epoch 251/300, Loss: 0.0031408669130003138, Test Accuracy: 46.39%\n",
            "Epoch 252/300, Loss: 0.0031252729053855162, Test Accuracy: 46.31%\n",
            "Epoch 253/300, Loss: 0.0031075899632825197, Test Accuracy: 46.28%\n",
            "Epoch 254/300, Loss: 0.0030900551731205443, Test Accuracy: 46.47%\n",
            "Epoch 255/300, Loss: 0.003080192890187448, Test Accuracy: 46.45%\n",
            "Epoch 256/300, Loss: 0.003061778238683734, Test Accuracy: 46.32%\n",
            "Epoch 257/300, Loss: 0.003046404727125661, Test Accuracy: 46.48%\n",
            "Epoch 258/300, Loss: 0.0030268456146177037, Test Accuracy: 46.38%\n",
            "Epoch 259/300, Loss: 0.003014522163413098, Test Accuracy: 46.40%\n",
            "Epoch 260/300, Loss: 0.002998722334775504, Test Accuracy: 46.38%\n",
            "Epoch 261/300, Loss: 0.002982027942352879, Test Accuracy: 46.32%\n",
            "Epoch 262/300, Loss: 0.002969718253331155, Test Accuracy: 46.48%\n",
            "Epoch 263/300, Loss: 0.002952626858071036, Test Accuracy: 46.37%\n",
            "Epoch 264/300, Loss: 0.0029414609968078324, Test Accuracy: 46.42%\n",
            "Epoch 265/300, Loss: 0.0029243383523385427, Test Accuracy: 46.38%\n",
            "Epoch 266/300, Loss: 0.0029117256463746647, Test Accuracy: 46.34%\n",
            "Epoch 267/300, Loss: 0.002897987902368242, Test Accuracy: 46.43%\n",
            "Epoch 268/300, Loss: 0.0028830282789341012, Test Accuracy: 46.35%\n",
            "Epoch 269/300, Loss: 0.002870039763977788, Test Accuracy: 46.48%\n",
            "Epoch 270/300, Loss: 0.002855990785135341, Test Accuracy: 46.41%\n",
            "Epoch 271/300, Loss: 0.00284292120333065, Test Accuracy: 46.34%\n",
            "Epoch 272/300, Loss: 0.0028310952332289085, Test Accuracy: 46.38%\n",
            "Epoch 273/300, Loss: 0.002812286183298807, Test Accuracy: 46.41%\n",
            "Epoch 274/300, Loss: 0.0028044259650406313, Test Accuracy: 46.30%\n",
            "Epoch 275/300, Loss: 0.002790762962873546, Test Accuracy: 46.29%\n",
            "Epoch 276/300, Loss: 0.0027768136607214896, Test Accuracy: 46.37%\n",
            "Epoch 277/300, Loss: 0.002761993092596197, Test Accuracy: 46.41%\n",
            "Epoch 278/300, Loss: 0.002748818992475025, Test Accuracy: 46.36%\n",
            "Epoch 279/300, Loss: 0.002736787100352933, Test Accuracy: 46.40%\n",
            "Epoch 280/300, Loss: 0.0027258174980425123, Test Accuracy: 46.38%\n",
            "Epoch 281/300, Loss: 0.002712623666827725, Test Accuracy: 46.32%\n",
            "Epoch 282/300, Loss: 0.0027022401651639254, Test Accuracy: 46.38%\n",
            "Epoch 283/300, Loss: 0.0026899651115252538, Test Accuracy: 46.32%\n",
            "Epoch 284/300, Loss: 0.00267561457789624, Test Accuracy: 46.42%\n",
            "Epoch 285/300, Loss: 0.0026632369307786827, Test Accuracy: 46.39%\n",
            "Epoch 286/300, Loss: 0.0026527357640600525, Test Accuracy: 46.35%\n",
            "Epoch 287/300, Loss: 0.002643273066701302, Test Accuracy: 46.39%\n",
            "Epoch 288/300, Loss: 0.0026288867753948863, Test Accuracy: 46.35%\n",
            "Epoch 289/300, Loss: 0.002616797818463255, Test Accuracy: 46.39%\n",
            "Epoch 290/300, Loss: 0.0026049305008866144, Test Accuracy: 46.33%\n",
            "Epoch 291/300, Loss: 0.0025932669720921714, Test Accuracy: 46.31%\n",
            "Epoch 292/300, Loss: 0.00258026281845418, Test Accuracy: 46.22%\n",
            "Epoch 293/300, Loss: 0.002571773420517605, Test Accuracy: 46.23%\n",
            "Epoch 294/300, Loss: 0.002561234738868414, Test Accuracy: 46.31%\n",
            "Epoch 295/300, Loss: 0.0025501772036635325, Test Accuracy: 46.37%\n",
            "Epoch 296/300, Loss: 0.0025344548759754374, Test Accuracy: 46.24%\n",
            "Epoch 297/300, Loss: 0.002527197924372874, Test Accuracy: 46.33%\n",
            "Epoch 298/300, Loss: 0.0025166352315235617, Test Accuracy: 46.30%\n",
            "Epoch 299/300, Loss: 0.002505141013583153, Test Accuracy: 46.33%\n",
            "Epoch 300/300, Loss: 0.002496123177825246, Test Accuracy: 46.37%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53      1000\n",
            "           1       0.60      0.53      0.56      1000\n",
            "           2       0.34      0.38      0.36      1000\n",
            "           3       0.30      0.29      0.29      1000\n",
            "           4       0.40      0.42      0.41      1000\n",
            "           5       0.34      0.34      0.34      1000\n",
            "           6       0.48      0.52      0.50      1000\n",
            "           7       0.54      0.50      0.52      1000\n",
            "           8       0.58      0.64      0.61      1000\n",
            "           9       0.55      0.50      0.52      1000\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.47      0.46      0.46     10000\n",
            "weighted avg       0.47      0.46      0.46     10000\n",
            "\n",
            "time: 2h 53min 29s (started: 2023-12-02 00:55:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.Sequential(nn.Flatten(), nn.Linear(32 * 32 * 3, 512), nn.Tanh(), nn.Linear(512, 256), nn.Tanh(), nn.Linear(256, 128), nn.Tanh(), nn.Linear(128, 10)).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5H5cZCDuaA",
        "outputId": "c471f560-a6d8-4ede-98b2-101210f38f64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 31.7 ms (started: 2023-12-02 03:49:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model2, train_loader, test_loader, num_epochs=120, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnd6ykUTEIrn",
        "outputId": "2ecff7b8-d97c-4687-de13-46fe2ee0f35f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120, Loss: 1.8600392635251495, Test Accuracy: 38.96%\n",
            "Epoch 2/120, Loss: 1.6882640814369334, Test Accuracy: 42.43%\n",
            "Epoch 3/120, Loss: 1.6143167977979835, Test Accuracy: 43.48%\n",
            "Epoch 4/120, Loss: 1.551621328159852, Test Accuracy: 44.71%\n",
            "Epoch 5/120, Loss: 1.4958151898853915, Test Accuracy: 46.19%\n",
            "Epoch 6/120, Loss: 1.4415796293101857, Test Accuracy: 47.23%\n",
            "Epoch 7/120, Loss: 1.38489851921854, Test Accuracy: 47.29%\n",
            "Epoch 8/120, Loss: 1.3294328470605348, Test Accuracy: 46.58%\n",
            "Epoch 9/120, Loss: 1.2698992878599038, Test Accuracy: 47.04%\n",
            "Epoch 10/120, Loss: 1.2136496130427106, Test Accuracy: 46.41%\n",
            "Epoch 11/120, Loss: 1.1531435336276499, Test Accuracy: 46.54%\n",
            "Epoch 12/120, Loss: 1.092544283915695, Test Accuracy: 48.14%\n",
            "Epoch 13/120, Loss: 1.0330894368433143, Test Accuracy: 47.67%\n",
            "Epoch 14/120, Loss: 0.9694620635520169, Test Accuracy: 46.01%\n",
            "Epoch 15/120, Loss: 0.9129247236389116, Test Accuracy: 47.83%\n",
            "Epoch 16/120, Loss: 0.8515014192154983, Test Accuracy: 47.11%\n",
            "Epoch 17/120, Loss: 0.800347710105752, Test Accuracy: 47.24%\n",
            "Epoch 18/120, Loss: 0.7399416259291534, Test Accuracy: 46.56%\n",
            "Epoch 19/120, Loss: 0.6846905794955185, Test Accuracy: 47.00%\n",
            "Epoch 20/120, Loss: 0.6336895622699137, Test Accuracy: 46.65%\n",
            "Epoch 21/120, Loss: 0.5817044883470693, Test Accuracy: 46.56%\n",
            "Epoch 22/120, Loss: 0.5399025581772329, Test Accuracy: 46.29%\n",
            "Epoch 23/120, Loss: 0.4887644479519575, Test Accuracy: 46.73%\n",
            "Epoch 24/120, Loss: 0.44470900673745767, Test Accuracy: 46.72%\n",
            "Epoch 25/120, Loss: 0.40790258910952665, Test Accuracy: 44.44%\n",
            "Epoch 26/120, Loss: 0.3767424488555752, Test Accuracy: 45.33%\n",
            "Epoch 27/120, Loss: 0.33717925388006087, Test Accuracy: 45.61%\n",
            "Epoch 28/120, Loss: 0.3079838737588011, Test Accuracy: 46.06%\n",
            "Epoch 29/120, Loss: 0.27981372421425044, Test Accuracy: 45.36%\n",
            "Epoch 30/120, Loss: 0.2516029001793378, Test Accuracy: 45.55%\n",
            "Epoch 31/120, Loss: 0.2257657049155853, Test Accuracy: 45.99%\n",
            "Epoch 32/120, Loss: 0.20127963664168666, Test Accuracy: 45.13%\n",
            "Epoch 33/120, Loss: 0.18031094395463199, Test Accuracy: 45.38%\n",
            "Epoch 34/120, Loss: 0.1632451296278102, Test Accuracy: 46.13%\n",
            "Epoch 35/120, Loss: 0.14114669112992723, Test Accuracy: 44.32%\n",
            "Epoch 36/120, Loss: 0.11979306456933819, Test Accuracy: 45.74%\n",
            "Epoch 37/120, Loss: 0.11719480055483845, Test Accuracy: 45.29%\n",
            "Epoch 38/120, Loss: 0.09119592796145955, Test Accuracy: 45.85%\n",
            "Epoch 39/120, Loss: 0.0934820538422454, Test Accuracy: 46.87%\n",
            "Epoch 40/120, Loss: 0.0773567762157343, Test Accuracy: 46.14%\n",
            "Epoch 41/120, Loss: 0.07690696462855381, Test Accuracy: 45.35%\n",
            "Epoch 42/120, Loss: 0.074772280608426, Test Accuracy: 45.55%\n",
            "Epoch 43/120, Loss: 0.06991237253787845, Test Accuracy: 45.30%\n",
            "Epoch 44/120, Loss: 0.04676315040903801, Test Accuracy: 44.33%\n",
            "Epoch 45/120, Loss: 0.0349268022043093, Test Accuracy: 46.12%\n",
            "Epoch 46/120, Loss: 0.026853462781129083, Test Accuracy: 46.01%\n",
            "Epoch 47/120, Loss: 0.03603051843804499, Test Accuracy: 46.24%\n",
            "Epoch 48/120, Loss: 0.020908632420938312, Test Accuracy: 45.99%\n",
            "Epoch 49/120, Loss: 0.01607618777612278, Test Accuracy: 46.32%\n",
            "Epoch 50/120, Loss: 0.01068036751991456, Test Accuracy: 46.34%\n",
            "Epoch 51/120, Loss: 0.00607849363953689, Test Accuracy: 46.36%\n",
            "Epoch 52/120, Loss: 0.005320608276758827, Test Accuracy: 46.85%\n",
            "Epoch 53/120, Loss: 0.003305338065818331, Test Accuracy: 46.63%\n",
            "Epoch 54/120, Loss: 0.0030917119449978755, Test Accuracy: 46.74%\n",
            "Epoch 55/120, Loss: 0.004004780864429446, Test Accuracy: 46.57%\n",
            "Epoch 56/120, Loss: 0.0025161188007174484, Test Accuracy: 46.58%\n",
            "Epoch 57/120, Loss: 0.0021001183663158824, Test Accuracy: 46.57%\n",
            "Epoch 58/120, Loss: 0.0019356027424911374, Test Accuracy: 46.64%\n",
            "Epoch 59/120, Loss: 0.0018447448096329839, Test Accuracy: 46.63%\n",
            "Epoch 60/120, Loss: 0.001732562573954954, Test Accuracy: 46.49%\n",
            "Epoch 61/120, Loss: 0.0016600641853820178, Test Accuracy: 46.68%\n",
            "Epoch 62/120, Loss: 0.0015815789259774151, Test Accuracy: 46.58%\n",
            "Epoch 63/120, Loss: 0.0015153369907425598, Test Accuracy: 46.55%\n",
            "Epoch 64/120, Loss: 0.00145099528068474, Test Accuracy: 46.70%\n",
            "Epoch 65/120, Loss: 0.0013921696664811656, Test Accuracy: 46.52%\n",
            "Epoch 66/120, Loss: 0.0013421408062339274, Test Accuracy: 46.62%\n",
            "Epoch 67/120, Loss: 0.001307937384207518, Test Accuracy: 46.55%\n",
            "Epoch 68/120, Loss: 0.0012589485150427031, Test Accuracy: 46.53%\n",
            "Epoch 69/120, Loss: 0.001216775555985456, Test Accuracy: 46.46%\n",
            "Epoch 70/120, Loss: 0.0011828269860355669, Test Accuracy: 46.48%\n",
            "Epoch 71/120, Loss: 0.001147235373358474, Test Accuracy: 46.56%\n",
            "Epoch 72/120, Loss: 0.0011138317620760676, Test Accuracy: 46.57%\n",
            "Epoch 73/120, Loss: 0.0010853994197762731, Test Accuracy: 46.52%\n",
            "Epoch 74/120, Loss: 0.0010551661493179822, Test Accuracy: 46.48%\n",
            "Epoch 75/120, Loss: 0.0010293154223206538, Test Accuracy: 46.44%\n",
            "Epoch 76/120, Loss: 0.0010027805279699939, Test Accuracy: 46.61%\n",
            "Epoch 77/120, Loss: 0.0009810517230021969, Test Accuracy: 46.55%\n",
            "Epoch 78/120, Loss: 0.0009545511758452197, Test Accuracy: 46.62%\n",
            "Epoch 79/120, Loss: 0.0009349801389597921, Test Accuracy: 46.47%\n",
            "Epoch 80/120, Loss: 0.0009143266045403209, Test Accuracy: 46.54%\n",
            "Epoch 81/120, Loss: 0.0008920671276272091, Test Accuracy: 46.55%\n",
            "Epoch 82/120, Loss: 0.0008735902331596966, Test Accuracy: 46.48%\n",
            "Epoch 83/120, Loss: 0.0008559457368257033, Test Accuracy: 46.55%\n",
            "Epoch 84/120, Loss: 0.0008382270684394561, Test Accuracy: 46.63%\n",
            "Epoch 85/120, Loss: 0.0008215099888827214, Test Accuracy: 46.57%\n",
            "Epoch 86/120, Loss: 0.0008030286078074362, Test Accuracy: 46.62%\n",
            "Epoch 87/120, Loss: 0.0007917442951925363, Test Accuracy: 46.60%\n",
            "Epoch 88/120, Loss: 0.000773554061230669, Test Accuracy: 46.58%\n",
            "Epoch 89/120, Loss: 0.0007610872957356583, Test Accuracy: 46.61%\n",
            "Epoch 90/120, Loss: 0.0007461155159220157, Test Accuracy: 46.64%\n",
            "Epoch 91/120, Loss: 0.0007336335895378655, Test Accuracy: 46.65%\n",
            "Epoch 92/120, Loss: 0.0007217355670663037, Test Accuracy: 46.60%\n",
            "Epoch 93/120, Loss: 0.0007089643906338662, Test Accuracy: 46.52%\n",
            "Epoch 94/120, Loss: 0.0006959491855936644, Test Accuracy: 46.42%\n",
            "Epoch 95/120, Loss: 0.0006840636614204062, Test Accuracy: 46.46%\n",
            "Epoch 96/120, Loss: 0.0006740563540256619, Test Accuracy: 46.56%\n",
            "Epoch 97/120, Loss: 0.0006633302701866702, Test Accuracy: 46.58%\n",
            "Epoch 98/120, Loss: 0.0006514981159957791, Test Accuracy: 46.59%\n",
            "Epoch 99/120, Loss: 0.0006421069159578849, Test Accuracy: 46.57%\n",
            "Epoch 100/120, Loss: 0.0006316348468318465, Test Accuracy: 46.55%\n",
            "Epoch 101/120, Loss: 0.0006234166949099735, Test Accuracy: 46.52%\n",
            "Epoch 102/120, Loss: 0.0006143982287645888, Test Accuracy: 46.57%\n",
            "Epoch 103/120, Loss: 0.0006054861529376322, Test Accuracy: 46.46%\n",
            "Epoch 104/120, Loss: 0.0005963785726602665, Test Accuracy: 46.61%\n",
            "Epoch 105/120, Loss: 0.0005885049748610287, Test Accuracy: 46.53%\n",
            "Epoch 106/120, Loss: 0.000578820997020048, Test Accuracy: 46.56%\n",
            "Epoch 107/120, Loss: 0.0005718524864984566, Test Accuracy: 46.47%\n",
            "Epoch 108/120, Loss: 0.0005641414905430973, Test Accuracy: 46.48%\n",
            "Epoch 109/120, Loss: 0.0005559691794631348, Test Accuracy: 46.50%\n",
            "Epoch 110/120, Loss: 0.000548682957218429, Test Accuracy: 46.55%\n",
            "Epoch 111/120, Loss: 0.0005418405826235552, Test Accuracy: 46.46%\n",
            "Epoch 112/120, Loss: 0.0005349841986028942, Test Accuracy: 46.53%\n",
            "Epoch 113/120, Loss: 0.0005277288123134491, Test Accuracy: 46.52%\n",
            "Epoch 114/120, Loss: 0.000520675208224642, Test Accuracy: 46.41%\n",
            "Epoch 115/120, Loss: 0.00051448091512882, Test Accuracy: 46.44%\n",
            "Epoch 116/120, Loss: 0.000508105503617156, Test Accuracy: 46.57%\n",
            "Epoch 117/120, Loss: 0.0005020721364463665, Test Accuracy: 46.53%\n",
            "Epoch 118/120, Loss: 0.0004966003872139555, Test Accuracy: 46.47%\n",
            "Epoch 119/120, Loss: 0.0004899007066329363, Test Accuracy: 46.38%\n",
            "Epoch 120/120, Loss: 0.0004845691079015963, Test Accuracy: 46.51%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.56      0.55      1000\n",
            "           1       0.60      0.54      0.57      1000\n",
            "           2       0.35      0.37      0.36      1000\n",
            "           3       0.31      0.34      0.33      1000\n",
            "           4       0.41      0.42      0.41      1000\n",
            "           5       0.35      0.33      0.34      1000\n",
            "           6       0.49      0.49      0.49      1000\n",
            "           7       0.54      0.49      0.51      1000\n",
            "           8       0.59      0.62      0.60      1000\n",
            "           9       0.52      0.49      0.50      1000\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.47      0.47      0.47     10000\n",
            "weighted avg       0.47      0.47      0.47     10000\n",
            "\n",
            "time: 1h 16min 47s (started: 2023-12-02 03:50:01 +00:00)\n"
          ]
        }
      ]
    }
  ]
}